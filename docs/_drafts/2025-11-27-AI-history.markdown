---
layout: post
title:  "AI发展历程"
date:   2025-11-27 23:44:54 +0800
categories: ascend
typora-root-url: ..
---

**总结自https://mp.weixin.qq.com/s/hFejZCXex_nw0Nrg-egP0g**

## 一、前世：AI出现前

### 1、唯一的高等智慧动物-人类

人脑很强大，但是记忆力和效率差，于是人类发明了计算机

### 2、第一台计算机诞生

计算机能记忆，但不能推导和思考，人类思考是否能让计算机也具备类似人类智能

## 二、今生：AI初生期（1956-1989）

### 1、AI概念定义

- 在1956年达特茅斯会议上，约翰·麦卡锡等科学家首次提出“**人工智能（Artificial Intelligence 缩写为AI）**”的专业术语，明确提出了“**让机器模拟人类智能**”的研究目标，这是AI成为独立学科的起点。
- 可以简要概括为**“人类智能”即**是：**让机器具备“感知、思考、决策、执行”的能力。**

### 2、自然语言处理（NLP）

* 1950年，图灵就提出“**如果一台机器能通过文本对话让人类无法分辨它是人还是机器，那它就具有了智能**”，这其实便是“自然语言处理（NLP）”的目标。只不过AI诞生后，刚好有了这个契机，“**自然语言处理（NLP）**”也成为了AI早期发展最重要的相辅相成的模块。

- **“自然语言处理（NLP）”**就是：**让计算机能够理解、解释、操纵和生成人类自然语言**，通俗点讲就是**教计算机“听懂人话、说人话、看懂人写的字、写出人能看懂的内容”。**

### 3、AI初生期案例分析

早期的机器翻译，下面我们以一个具体的例子来说明：

> The apple is red.

机器翻译的原理：

- 第一步：查词典
- 第二步：调整顺序

总结：只会按规则执行，翻译出来的文字死板且没有预感，不像人类的表达

### 4、AI初生期小结

虽然有**自然语言处理（NLP）**的加持，但AI基本都是死板的按人类制定的规则去执行，比较死板，不够灵活。

如果把AI比作一个人类，我认为这一阶段，他最多算是**一个只会死记硬背的小学生，不懂变通**，一旦遇到超出自己死记硬背以外的其他内容，就一无所知，我们暂且把这一阶段的AI称作**“规则式AI”**。

## 三、今生：AI成长期（1990-2016）

### 1、机器学习出现

那么，什么是机器学习：**让机器从数据中自己学习规律，而不是仅仅依靠人类为它编写固定的指令。**

### 2、AI成长期案例分析 - 垃圾邮件过滤系统

如果按AI初生期（1956-1989）的方法，只能按照既定规则来，比如：

* 如果邮件标题里出现 “免费” 这个词，就标记为垃圾邮件
* 如果发件人地址包含 “spam” ，就标记为垃圾邮件
* 等等...

那么，如果在AI成长期（1990-2016），我们可以怎么做？

- 第一步：准备“学习资料”

  - 1000封已知的垃圾邮件 （标为“垃圾”）
  - 1000封已知的正常邮件 （标为“正常”）

- 第二步：让机器自己“找规律”

  机器会开始埋头苦读这些邮件，并进行统计分析。他会自动发现：

  - 在“垃圾邮件”里，词语“免费”、“优惠”、“发票”出现的概率非常高。

  - 在“正常邮件”里，词语 “会议”、“项目”、“放假”、“通知” 出现的概率非常高。

    最终，机器形成了一套自己的判断标准 。

- 第三步：实际运作

​	这时，一封新邮件来了，标题是 “关于国庆放假的通知” 。

​	这时，机器会分析这封邮件的内容。

​	他发现，“放假”、“通知”这些词在他的记忆里，和“正常邮件”的关联度非常高。

​	而“免费”、“优惠”这些垃圾邮件高频词一个都没出现。

​	于是，机器认为：这是一封正常邮件。

通过这个案例，我们会发现有了机器学习的加持，AI从“规则式”的死板应用加上了“AI模型分析”，机器会自己学习、自己总结规律了。

### 3、AI模型出现

那么机器通过自己学习，自己总结出的规律，这其实就是**AI模型（Model）！**

那么到底什么是AI模型：**一个通过大量数据训练出来的、能够识别特定模式或规律的数学函数或程序。**通俗点讲就是**从数据中提炼出的“规律”或“经验”本身。**

### 4、机器学习方法：监督学习

“监督学习”，即：给机器学习的训练数据都带有明确的“标签”（如标注好“垃圾”还是“正常”）。

### 5、AI成长期小结

**如果还是把AI比作一个人类，我认为这一阶段，他可以算是一个靠刷题总结规律的中学生了：**比如可能针对中学的生物这门课，刷了大量的题（包含答案），能自己总结出规律和方法，再遇到同样类型题的时候，这位中学生能得心应手的回答上来。

而通过统计大量题或内容然后总结规律，我们可以暂且把这阶段的AI称为**“统计式AI”**。

**但是，有一个很重要的问题：**

这位中学生刷的是某一学科的题，虽然很厉害，但他**可能偏科**，比如没有去刷物理的题，在遇到物理学科一个他从没做过的题，他可能还是做不出来。

## 四、今生：AI爆发期（2017年至今）

### 1、AI模型架构演进

我们通过**机器学习（监督学习）**训练出了**AI模型**（通常用**“朴素贝叶斯模型架构”**），让模型自己判断收到的邮件是不是垃圾邮件，看起来更高效了。

**但实际上有个缺点：**

他是个“拆词专家”，他会把邮件拆成一堆零散的词，不会关心词的顺序和句子意思！ 比如“钱转给你”和“你把钱转走”，对他来说都是一堆含有“钱”、“转”的词，意思差不多。他无法理解前者是正常收款，后者可能是诈骗预警。

**这时候RNN架构（循环神经网络）出来了：**

他不再拆散邮件，而是尝试逐词阅读整个句子，并努力记住前面读过的内容。

他终于有了初步的“上下文”概念，能理解一些简单的句子结构了。

但他有个关键的问题：他有“健忘症”！如果邮件很长，他读到结尾时，早就忘了开头说了什么。比如，邮件开头说“关于上次开会的项目报告...”，结尾说“...请支付费用”，他可能就忘了开头是正经事，只记得结尾要钱，从而误判。

**因为有“健忘”的问题，所以CNN架构（卷积神经网络）出来了：**

他每次只关注相邻的几个词。比如，看到“难以置信的”和“优惠”时，他能敏锐地感觉到这是个广告短语。看到“验证您的”和“账户”时，他知道这可能是个安全提示。通过这种方式可以让他的效率变得更高（可以同时处理多个相邻词），擅长捕捉局部短语特征。通过这种方式，其实可以变相解决“健忘”的问题，

**但有一个关键问题，他无法同时看到邮件全文：**

比如，一封邮件可能开头很长一段都是正常的商务沟通，只在最后一句巧妙植入诈骗链接，他可能因为前面都是正常局部信息而放过它。而这也导致了他难以理解邮件整体的逻辑和核心意图。

**我们简单总结一下，以上的AI模型通过架构的优化和演进，能力在逐步提升，但他们也有明显的缺陷：**

● “不懂语法”：只看零散关键词。

● “认真但健忘”：处理长文效率低。

● “眼光狭隘”：缺乏全局观。

### 2、Transformer架构出现

**2017年**，Google的研究团队发表了一篇名为《Attention Is All You Need》的论文，正式提出了**Transformer架构**。

**Transformer架构**因此诞生！

**我们来看看Transformer架构到底是怎么工作的，我们还是以邮件垃圾过滤为例：**

假设有一封可疑邮件，内容是：“尊敬的客户，恭喜您获得10W奖金！请点击唯一链接 http://xxx.com领取”

**第一步：同时查看所有关键信息（并行处理）**

以前的RNN架构要一个字一个字读，而**Transformer架构**可以一瞬间看到所有词

**第二步：划重点并分析（自注意力机制）**

他会给词与词之间画上“关联线”，比如 “奖金”和哪个词关联最强？他发现“奖金”和 “链接” 、“领取” 关联非常紧密。这种“中奖-链接-领取”的模式，经典得就像它的办案手册里写的“诈骗三件套”。

**第三步：全局推理，看穿意图**

他看清了整封邮件的逻辑 ：“这是一封群发邮件（尊敬的客户），用虚假的好消息（巨额奖金）作为诱饵，其最终意图是诱导收件人点击一个可疑链接（http://xxx.com）。”

它理解的是邮件的整体意图，而不是机械的匹配关键词。

**第四步：做出最终决定**

他非常有把握地得出结论： “这是一封钓鱼诈骗邮件！” 然后将它扔进垃圾箱。

通过这个例子，我们看到用了Transformer架构的垃圾邮件过滤器，通过**“自注意力机制”**可以做出精准的判断，那么什么是“**自注意力机制**”，通俗点理解即是：**模型在处理一句话时，能瞬间看到所有的词，并智能地判断出哪些词之间关系更重要。**

**正是Transformer架构的革命性突破，成为了引爆AI爆发期最关键的技术基石。**



### 3、AI大模型出现

有了Transformer架构，那么AI模型就可以得到革命性的改进和优化，基于这个契机，OpenAI在**2018年**推出了生成式模型：**GPT-1**，**GPT-1拥有1.17亿参数**

在诸如之后快速发展，OpenAI相继在2019年推出了**GPT-2（参数扩大到15亿）、**在2020年推出了**GPT-3（参数规模达到1750亿 ）。**

随着参数规模不断扩大的AI模型出现，这也正是**为了解决AI成长期（1990-2016）AI模型“偏科”的问题**，让AI模型具备更通用更强大的知识储备，可以覆盖多个领域。

**基于此，大模型（ Large Model 缩写为\**\**LM）**由此而生！

那么，什么叫大模型？基础定义为：**大规模人工智能模型。**

那么这里的**“大规模”**具体是什么？即泛指**参数规模巨大**的模型。通常我们把**参数规模在10亿以上**的可以算是**入门级的大模型**，但发展到今天（2025），我们通常把**参数规模在100亿以上算作大模型，**类如混元大模型旗下的TurboS大模型参数量为5600亿。

### 4、大模型、中模型、小模型

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/j3gficicyOvavSZsbSmdnMumMXZibBPGboKFS9NVkyBf3J5XRvicqqGicgA3DdSeBI4eEsia2U3rGCpTsasVGiaLiaxic6w/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1#imgIndex=10)

### 5、大语言模型

我们和机器沟通、让机器理解我们的语言都算是在语言层面最直接的应用，那在大模型出来后，最初的形式就是**大语言模型（ Large Language Model 缩写为LLM ）**：

● Large（大）：指参数数量巨大，另外还指训练的数据量巨大

● Language（语言）：自然语言。

● Model（模型）： 能识别特定模式或规律的计算模型

而我们之前提到的在2020年推出的GPT-3可谓是实实在在的大语言模型（拥有1750亿参数），再到后来继续演进，OpenAI在2023年正式推出了GPT-4（参数量相比GPT-3更大），而且更强大的是：**GPT-3只能处理文本**，而**GPT-4既可以处理文本也可以处理图像**。类似的大语言模型还有我们鹅厂的Turbos、Deepseek等等。

### 6、除了大语言模型还有哪些模型？

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/j3gficicyOvavSZsbSmdnMumMXZibBPGboKa1dibC37YfXpDznHKDTGMaU7tL7JmE2oQvpOefPBknP0eCCk4akg26Q/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1#imgIndex=11)

### 7、机器学习方法：无监督学习

**那么GPT之类的AI大模型是怎么训练（这阶段通常称为“预训练”）出来的呢？**

其实，同样也是用了机器学习，但可能会更“深度”，这里的“**深度**”主要指：**在机器学习的过程中分很多步骤，每一步骤学到一些不同的规律，从简单到复杂，逐步深入**。因为大模型的参数量非常大，给到模型训练的数据量也巨大，我们不能再通过只给模型2000个数据（标注）的方式让他自己学习和总结规律。GPT之类的通用大模型基本要吃掉互联网当下存在的所有知识，人工不可能给某一条知识都去做标记告诉模型哪些是对的哪些是错的，只能塞给机器无数的知识，但要让机器自己去总结规律，得出相应的“正确”或“错误”（在监督学习下，原来应该是人工标注的工作）。

那么这种机器学习的方法，我们称之为“**无监督学习**”。

### 8、深度神经网络、深度机器学习和传统机器学习

而因为由于大模型巨大的参数量和训练量，需要更复杂的网络结构。之前提到的RNN、CNN、Transformer等，都属于“**深度神经网络”**的范畴。有了“**深度神经网络**”的支撑，我们通常把对大模型预训练时的机器学习范式称为“**深度机器学习**”，也可以简称为“**深度学习**”，那么再回到AI成长期（1990-2016）当时其实也用了机器学习，我们把这阶段的机器学习范式称之为“**传统机器学习**”。

### 9、以ChatGPT、SD等案例分析

### 10、提示词工程

**提示词工程**是一门与AI有效沟通的链接方式，通过以上例子我们可以稍微总结下整体原则：**你给AI的提示词越清晰、越具体，你得到的结果就越好**。掌握这项技能，你将能真正释放大模型的巨大潜力。

可以看出，生成的图片更符合预期，但大家有没有发现一点，我们向AI**既输入了文本又输入了图片**（小白的照片），而AI给我们输出了一个最终的图片，这和之前的ChatGPT体验可完全不一样啊！（笔者注：其实，最新的ChatGPT已经支持既输入文本又输入图片，基于GPT-4o大模型）

### 11、多模态、单模态

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/j3gficicyOvavSZsbSmdnMumMXZibBPGboKsw84icmELywQKdCzq7oRibZFpUUbrlaRWzbAHpvUob6gJRL3FvHBC6bg/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1#imgIndex=18)

### 12、开源、闭源

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/j3gficicyOvavSZsbSmdnMumMXZibBPGboKuI4uhKCz6Jepfx6j5KU8UgwYrAC9ziaNpZH53DcouE7fvDfZ7TibgqJg/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1#imgIndex=19)

### 13、智能体的出现

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/j3gficicyOvavSZsbSmdnMumMXZibBPGboKn2McqXyAic432nM2G0IeBbofSrkiaYNLyXO5QLZZZAsJRVffnvK3BDTA/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1#imgIndex=20)

一个更好理解的定义是：**能够感知环境、进行决策，并自主采取行动以实现某种目标的系统或程序。**

**简要总结：**

● **大模型是智能体的 “能力基础”**：没有大模型，智能体就不会理解和思考，只能机械执行固定指令。

● **智能体是大模型的 “落地延伸”**：光有大模型只能 “纸上谈兵”，智能体通过搭配工具、设定目标、让大模型的能力从 “说” 变成 “做”。

● **两者是 “分工协作”**：大模型负责 “想清楚”，智能体负责 “做到位”。

### 14、如何开发一个智能体应用？

**大概可以是以下流程：**

1.**需求确认及策划 ：**明确项目到底要做什么，想通过AI解决什么问题或者提升什么体验

2.**技术选型及架构设计 ：**用什么大模型（是智能体的大脑）？智能体平台/框架选择？用什么工具链？

3.**核心开发 ：**核心开发过程

4.**智能体调优及测试 ：**智能体调优的方式？

5.**项目上线运营与迭代：**持续运营及优化迭代

为什么说“**智能体调优**”这个环节最重要，是因为我们做一个AI智能体应用，AI效果有没有达到我们的预期，智能体调优有没有做到最好是最关键的，而在上面三个项目的智能体调优方法基本一致，这也说明对于大部分智能体应用调优的方法是具备一定通用性的，这里面的提示词工程在前面已经提到过，我们不再赘述。我们会重点关注在新出现的两个专业术语：“RAG”和“微调”，我们在下面慢慢来探讨。

### 15、检索增强生成（RAG）

**检索增强生成（Retrieval-Augmented Generation 缩写为RAG），**拆分一下解释即是：

● **检索：**从外部知识库中查找与问题相关的信息。

● **增强：**用检索到的信息来“增强”或“补充”大模型的知识。

● **生成：**大模型基于这些补充的信息，生成更准确、更可靠的答案。

**通俗易懂的一句话解释就是：**智能体的大脑（大模型）进行输出内容之前，先让它主动去一个庞大的知识库（如文档、数据库、互联网）中“查阅资料”，然后根据查到的资料来组织和生成答案。

### 16、微调：基于监督学习和强化学习

我们在智能体调优的过程中，提示词工程、RAG等方式其实都只是改变的是模型的输入阶段，让输入更有效，而想更好的去优化智能体的输出，还要用到：**微调。**提示词、RAG等改变了输入环节，而微调本质上则改变了AI模型（对于开源大模型而言是模型副本，对于闭源大模型而言是“适配层”）。

监督学习是给了模型标准的答案（比如我们告诉模型是goodcase还是badcase），但大家试想一下如果这个数据量特别巨大，每次让人工去标注所有的将非常不现实。而基于人工反馈的强化学习（RLHF）则是更高效的方法，用一个评分奖励模型，我们让AI学习这个评分标准，然后通过一次又一次的学习生成高分，从而达到我们想要的效果。

而通过以上的智能体调优方法，目的就是为了让我们做出来的这个AI应用更符合我们的预期，比如AI回答的更准确、更趣味。

### 17、大模型的幻觉问题

但其实，我们在项目过程中有时还是会发现AI回答的不是100%正确，而这正是大模型的“幻觉”问题：**大模型生成看似合理但事实上错误、荒谬或虚构信息的行为，**简单来说就是AI在一本正经地胡说八道。

而我们上面用到了一些智能体调优的方法一定程度上本质就是为了解决“幻觉”问题，而“幻觉”问题产生的原因主要就是我们期待AI去输出一些内容，但这些内容又超出了AI的认知时，他可能就会乱说或说错。

除了通过RAG、提示词工程、微调等方法调优智能体，提升我们AI输出的准确性外，我们还可以比如：

● 答案溯源：让模型增加二次校验（要求模型在生成答案时，注明引用的源文）

● 自我批判：让模型对自己生成的答案进行一次自我审查

● 高准确性信息采用固定信源：比如我们的AI赛事助手的赛程、赛事等信息让AI去查固定的接口，而不是走联网搜索

● 等等

简要总结，幻觉是当前大模型的通用问题，包括我们之前谈到的GPT系列以及现在所有的通用大模型都会有“幻觉”问题，而我们当前所有的调优手段，如RAG、提示词工程、SFT、RLHF等，其重要目标之一就是最大限度地管理和减少幻觉，但其实并不能完全消除它。因此，我们除了做好AI输入阶段的优化外，对AI的输出阶段同样应该保持谨慎，这也是每个AI从业者应有的重要意识。

### 18、AI爆发期小结

AI爆发期，从2017年到现在，短短的几年时间，AI经历了飞速的发展，大模型百花齐放，相关的智能体应用也层出不穷。这阶段（也是我们正在经历的）的AI，我认为他已经是一个读遍天下书的大学生，拥有了丰富的知识积累加上了一定量的实习经验，下一阶段就是未来，他应该会走上社会，成为一个职场上的专业人员，把多年积累下来的知识和实习期积累的经验更好的应用在职场上，同样的，我们可以把这阶段的AI称为“深度学习/大模型AI”。

## 五、未来

不知道大家有没有去看2025英伟达GTC大会，这个大会点出了很多未来和AI更有想象空间的模块，如AGI、具身智能、量子计算、6G、人机协同等，感兴趣的同学可以去详细了解。

但很多时候更需要我们思考的是：为什么要用AI？AI现在能做什么以及未来能做什么？用了AI后可以改变什么？如果不用AI会怎么样？

在未来，AI不再是一个工具，更是我们重要的“伙伴”。
