---
layout: post
title:  "CUTLASS cute"
#date:   2025-11-11 11:18:26 -0800
categories: CUDA
typora-root-url: ..
---

## Library Organization

CuTe is a header-only C++ library, so there is no source code that needs building. Library headers are contained within the top level [`include/cute`](https://github.com/NVIDIA/cutlass/tree/main/include/cute) directory, with components of the library grouped by directories that represent their semantics.

| Directory                                                    | Contents                                                     |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| [`include/cute`](https://github.com/NVIDIA/cutlass/tree/main/include/cute) | Each header in the top level corresponds to one of the fundamental building blocks of CuTe, such as [`Layout`](https://github.com/NVIDIA/cutlass/tree/main/include/cute/layout.hpp) and [`Tensor`](https://github.com/NVIDIA/cutlass/tree/main/include/cute/tensor.hpp). |
| [`include/cute/container`](https://github.com/NVIDIA/cutlass/tree/main/include/cute/container) | Implementations of STL-like objects, such as tuple, array, and aligned array. |
| [`include/cute/numeric`](https://github.com/NVIDIA/cutlass/tree/main/include/cute/numeric) | Fundamental numeric data types that include nonstandard floating-point types, nonstandard integer types, complex numbers, and integer sequence. |
| [`include/cute/algorithm`](https://github.com/NVIDIA/cutlass/tree/main/include/cute/algorithm) | Implementations of utility algorithms such as copy, fill, and clear that automatically leverage architecture-specific features if available. |
| [`include/cute/arch`](https://github.com/NVIDIA/cutlass/tree/main/include/cute/arch) | Wrappers for architecture-specific matrix-matrix multiply and copy instructions. |
| [`include/cute/atom`](https://github.com/NVIDIA/cutlass/tree/main/include/cute/atom) | Meta-information for instructions in `arch` and utilities like partitioning and tiling. |

`cute::print_layout` must have rank-2. 

## variable naming convention in Cute

Optimizing tool selection...Short answer: it's a naming convention. tCgA means "the tiled/partitioned tensor (tC) produced from the global tensor gA".

Explanation and how to read these names
- Prefixes:
  - `g` = global/gmem slice (e.g. `gA`, `gB`, `gC`, `gD` are the GMEM sub-tensors produced by `local_tile`).
  - `t` = tiled / partitioned tensor (result of applying a tiler/partitioner).
  - `s` = smem (a SMEM-backed tensor or smem view).
  - `r` = fragment/ register-like descriptor (a fragment or descriptor used by the MMA).
  - other letters may appear to indicate other transformations (e.g., `tCtAcc` is a tiled TMEM accumulator).
- Middle letter(s) after `t` identify the partitioning pattern or which partition API was used:
  - in this file the code uses methods like `cta_mma.partition_A`, `partition_B`, `partition_C`. The name `tC` is the token used by the authors to indicate that partitioning pattern (the exact token is just a human-readable label used consistently in the example).
- Suffix is the source tensor the partition was applied to:
  - `gA`, `gB`, `gC`, `gD` are the global tensors (slices) the kernel works on.

Concrete mapping from the example
- `gA`, `gB`, `gC`, `gD` — global (GMEM) tile slices returned by `local_tile`.
- `tCgA = cta_mma.partition_A(gA)` — apply the `tC` partitioning pattern (CTA/MMA partitioning) to `gA`; result is a tensor partitioned for the MMA/CTA usage (shape printed in the example).
- `tCgB = cta_mma.partition_B(gB)` — same, for `gB`.
- `tCgC`, `tCgD` — partitioned versions of `gC`/`gD` (the C/D GMEM tiles).
- Related names in the file:
  - `tCsA`, `tCsB` — SMEM-backed tensors (SMEM views) for the same partitioning pattern.
  - `tCrA`, `tCrB` — fragment/descriptor views prepared for the MMA (register/fragment descriptors).
  - `tCtAcc` — tiled TMEM accumulator produced by `make_fragment_C`.

Why this is useful
- The compact mnemonic `tXgY` documents both what transform was done (`tX`) and what it was applied to (`gY`), so you can quickly see the provenance and role of each tensor in the kernel (GMEM → partition → SMEM → fragment → TMEM, etc.).

If you want, I can:
- Add a short comment block in 02_mma_tma_sm100.cu that documents this naming convention (makes examples easier to scan).
- Produce a one-line table of the common name tokens (`g`, `t`, `s`, `r`, `CtAcc`, etc.) and their meanings and insert it near the top of the example. Which would you prefer?

## PermutationMNK in AtomLayoutMNK
https://github.com/NVIDIA/cutlass/discussions/1345

![ALT](https://docs.nvidia.com/cutlass/latest/_images/gemm-hierarchy-with-epilogue.png)



### MMA Atom

{% raw %}
```c++
struct SM70_8x8x4_F32F16F16F32_NT
{
  using DRegisters = float[8];
  using ARegisters = uint32_t[2];
  using BRegisters = uint32_t[2];
  using CRegisters = float[8];

  // Register asm fma
  CUTE_HOST_DEVICE static void
  fma(float         & d0, float         & d1, float      & d2, float      & d3,
      float         & d4, float         & d5, float      & d6, float      & d7,
      uint32_t const& a0, uint32_t const& a1,
      uint32_t const& b0, uint32_t const& b1,
      float    const& c0, float    const& c1, float const& c2, float const& c3,
      float    const& c4, float    const& c5, float const& c6, float const& c7)
  {
    asm volatile("mma.sync.aligned.m8n8k4.col.row.f32.f16.f16.f32"
                 "{%0,  %1,  %2,  %3,  %4,  %5,  %6,  %7},"
                 "{%8,  %9},"
                 "{%10, %11},"
                 "{%12, %13, %14, %15, %16, %17, %18, %19};"
        : "=f"(d0), "=f"(d1), "=f"(d2), "=f"(d3),
          "=f"(d4), "=f"(d5), "=f"(d6), "=f"(d7)
        :  "r"(a0),  "r"(a1),
           "r"(b0),  "r"(b1),
           "f"(c0),  "f"(c1),  "f"(c2),  "f"(c3),
           "f"(c4),  "f"(c5),  "f"(c6),  "f"(c7));
  }
};

template <>
struct MMA_Traits<SM70_8x8x4_F32F16F16F32_NT>
{
  using ValTypeD = float;
  using ValTypeA = half_t;
  using ValTypeB = half_t;
  using ValTypeC = float;

  using Shape_MNK = Shape<_8,_8,_4>;
  using ThrID   = SM70_QuadPair;
  using ALayout = SM70_8x4_Col;
  using BLayout = SM70_8x4_Col;
  using CLayout = SM70_8x8_32b;
};
```
{% endraw %}

#### Operation struct’s name

A CuTe Operation struct’s name principally encodes the PTX instruction it wraps. These often include

- its first supported architecture,
- the M, N, and K dimensions that it accepts,
- the types that it takes, and
- the arrangement of the A and B inputs.

For example, the Volta section below will refer to the `SM70_8x8x4_F32F16F16F32_NT` Operation struct defined in [`include/cute/arch/mma_sm70.hpp`](https://github.com/NVIDIA/cutlass/tree/main/include/cute/arch/mma_sm70.hpp).

- “SM70” refers to Volta.
- “8x8x4” refers to M = 8, N = 8, and K = 4, the dimensions of the MMA operation that the quadpair performs (see below). This is reflected in the PTX as `.m8n8k4.`.
- “F32F16F16F32” refers to the element types of the four matrix operands A, B, C, and D. An MMA computes D = C + A * B, so we read the types from left to right: D is F32 (`float`), A is F16 (half), B is F16 (half), and C is F32 (`float`). This is reflected in the PTX instruction name as `.f32.f16.f16.f32`.
- “NT” means that the PTX instruction is designed for inputs A as M-major (not transposed, column-major) and inputs B as N-major (transposed, row-major). This is reflected in the PTX instruction name as `.col.row.`.

##### Type aliases

An Operation struct has four public type aliases: `DRegisters`, `ARegisters`, `BRegisters`, and `CRegisters`. For example, the `SM70_8x8x4_F32F16F16F32_NT` Operation struct defined in [`include/cute/arch/mma_sm70.hpp`](https://github.com/NVIDIA/cutlass/tree/main/include/cute/arch/mma_sm70.hpp) defines these as follows.

```
using DRegisters = float[8];
using ARegisters = uint32_t[2];
using BRegisters = uint32_t[2];
using CRegisters = float[8];
```



This shows how many values each thread will pass into the PTX instruction for each of the matrices A, B, C, and D. For this Operation, each thread passes 8 F32 values each for C and D (hence `float[8]`), and 4 F16 values each for A and B (hence `uint32_t[2]`; the instruction packs two 16-bit F16 values in each of the two 32-bit `uint32_t` values).

#### Contents

An `MMA_Traits` specialization defines the following public type aliases.

- `ValTypeD`: Logical compute type of the D matrix
- `ValTypeA`: Logical compute type of the A matrix
- `ValTypeB`: Logical compute type of the B matrix
- `ValTypeC`: Logical compute type of the C matrix
- `Shape_MNK`: Logical MxNxK shape of the MMA operation
- `ThrID`: Logical thread mapping within the single MMA operation (specifying the thread, quadpair, warp, or warpgroup view)
- `ALayout`: Mapping of (thread,value) pairs to coordinates in the MxK A matrix
- `BLayout`: Mapping of (thread,value) pairs to coordinates in the NxK B matrix
- `CLayout`: Mapping of (thread,value) pairs to coordinates in the MxN C matrix



## Tiled MMA and Copy

The Tiled MMA or Copy are tilings of MMA atoms resp. Copy atoms across threads and data, with possible permutations applied to the resulting tiling. This layer is most analogous to the warp level tiling of MMA instructions in CUTLASS 2.x. However, it views the tiling from the perspective of all threads participating in the operation and generalizes the concept to copy operations as well. The purpose of this layer is to build composable GPU micro-kernels out of a plethora of hardware accelerated math and data movement operations, each with their unit layouts in threads and data. The tiled MMA and Copy types present all these various hardware accelerated CuTe Atoms with a single, consistent API.

The resulting tiled operation acts as a single MMA or copy operation that users can invoke in the “inner” loop of the three-nested-loops pseudocode at the top of this document using `cute::gemm()` or `cute::copy()`.

We call this API “tiled” because it constructs larger operations out of the Atoms provided by CuTe, as if fitting together individual tiles to build a reusable component of a mosaic. For example, CuTe might provide an MMA Atom that users can call on a single warp, for fixed M, N, and K dimensions. CUTLASS can then use CuTe operations like `make_tiled_mma` to turn this Atom into an operation that works on an entire thread block, for larger M, N, and K dimensions.



Here we use a specialized function, `make_tmem_copy`, to deduce a TV-layout from the copy atom and TMEM tensor and create the TiledCopy. One important thing to know about this function is that *it is hardcoded to use 4 warps, or 1 warpgroup.* As mentioned in the earlier section, certain regions of TMEM are only accessible by a corresponding warp in a warpgroup, based on the warp index mod 4. This [diagram from the PTX manual](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#layout-d-m-128-cta-group-1) shows how the data is assigned to warps for our example:

![img](https://i0.wp.com/research.colfax-intl.com/wp-content/uploads/2025/04/tcgen05-data-path-layout-d1.png?resize=960%2C386&ssl=1)

```c++
template <class MMA_Op,
          class MMAThrLayout = Layout<Shape<_1,_1,_1>>,
          class Permutations = Tile<Underscore,Underscore,Underscore>>
CUTE_HOST_DEVICE constexpr
auto
make_tiled_mma(MMA_Atom<MMA_Op> const& mma_atom,
               MMAThrLayout     const& thr_layout   = {},
               Permutations     const& permutations = {});
```

`MMAThrLayout` is to replicate atom across threads; `Permutations` is to replicate values on top of replicating across threads.

### An example



## Tiled Copy

https://leimao.github.io/blog/CuTe-ldmatrix/

## [Epilogue Visitor Tree](https://dl.acm.org/doi/10.1145/3620666.3651369)

